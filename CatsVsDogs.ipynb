{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "031c7ce6",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9106ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import zipfile\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "from numba import cuda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8118453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used for local GPU usage\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2853723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting seeds for replicating similar results\n",
    "seed = 42\n",
    "random.seed(42)\n",
    "np.random.seed(seed=seed)\n",
    "tf.random.set_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ade66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_zip = \"dogs-vs-cats-redux-kernels-edition/train.zip\"\n",
    "# zip_ref = zipfile.ZipFile(train_zip,\"r\")\n",
    "# zip_ref.extractall(\"working/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dc8a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_zip = \"dogs-vs-cats-redux-kernels-edition/test.zip\"\n",
    "# zip_ref = zipfile.ZipFile(test_zip,\"r\")\n",
    "# zip_ref.extractall(\"working/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f15237ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Paths for working, train, validation and test directories\n",
    "work = \"working/\"\n",
    "train_path = work + \"train/\"\n",
    "valid_path = work + \"valid/\"\n",
    "test_path = work + \"test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5958752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining cat and dog paths for train and validation sets\n",
    "dog_train_path = train_path + \"dog/\"\n",
    "cat_train_path = train_path + \"cat/\"\n",
    "dog_valid_path = valid_path + \"dog/\"\n",
    "cat_valid_path = valid_path + \"cat/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1f4991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code used to create images in the paths defined to use Tensorflows Flow from directory\n",
    "try: \n",
    "    os.mkdir(valid_path)\n",
    "    os.mkdir(dog_train_path)\n",
    "    os.mkdir(cat_train_path)\n",
    "    os.mkdir(dog_valid_path)\n",
    "    os.mkdir(cat_valid_path)\n",
    "except:\n",
    "  print(\"dir already exists\")    \n",
    "\n",
    "cat_files = [img for img in os.listdir(train_path) if img[:3] == \"cat\"]\n",
    "dog_files = [img for img in os.listdir(train_path) if img[:3] == \"dog\"]\n",
    "\n",
    "cat_files_train = random.sample(cat_files, k=round(len(cat_files) * 0.8))\n",
    "dog_files_train = random.sample(dog_files, k=round(len(dog_files) * 0.8))\n",
    "\n",
    "cat_files_valid = list(set(cat_files) - set(cat_files_train))\n",
    "dog_files_valid = list(set(dog_files) - set(dog_files_train))\n",
    "\n",
    "[os.rename(train_path + file, dog_train_path + file) for file in dog_files_train]\n",
    "[os.rename(train_path + file, dog_valid_path + file) for file in dog_files_valid]\n",
    "[os.rename(train_path + file, cat_train_path + file) for file in cat_files_train]\n",
    "[os.rename(train_path + file, cat_valid_path + file) for file in cat_files_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb9487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb82e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Batch size, augmentation levels, class num image target size\n",
    "batch_size = 32\n",
    "augment_value = 0.05\n",
    "num_classes = 2\n",
    "img_size = (299, 299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef3abc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Augmenting and Importing Data using ImageDataGenerator and Flow From Directory modules\n",
    "    #from Tensorflow for both training and validation datasets\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1. / 255,\n",
    "    rotation_range = augment_value,\n",
    "    height_shift_range = augment_value,\n",
    "    width_shift_range = augment_value,\n",
    "    shear_range = augment_value,\n",
    "    zoom_range = augment_value,\n",
    "    cval = augment_value,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale = 1. / 255\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size = img_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size = img_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d470f420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#Similarly importing test data using flow from directory\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1. / 255\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size = img_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = None,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31051e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91bc84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a custom CNN Classifier\n",
    "with tf.device('/cpu:0'):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, 7, activation = \"relu\", padding = \"same\", \n",
    "                                  input_shape = [299, 299, 3], strides = (1, 1)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Conv2D(64, 7, activation = \"relu\", padding = \"same\", strides = (1, 1)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D(2))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.Conv2D(64, 3, activation = \"relu\", padding = \"same\", strides = (1, 1)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Conv2D(64, 3, activation = \"relu\", padding = \"same\", strides = (1, 1)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D(2))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.Conv2D(64, 3, activation = \"relu\", padding = \"same\", strides = (1, 1)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Conv2D(64, 3, activation = \"relu\", padding = \"same\", strides = (1, 1)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D(2))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(2, activation=\"softmax\"))\n",
    "#I got a maximum accuracy of 0.85 with this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e04f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3083b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining model checkpoint and earlystopping callbacks to retrieve the best\n",
    "    #parameters after the validation accuracy stops improving\n",
    "callbacks_list = [\n",
    "    ModelCheckpoint(work, monitor = 'val_accuracy', verbose = 1, save_best_only = True),\n",
    "    EarlyStopping(monitor = 'val_accuracy', patience = 2, verbose = 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f386af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the optimizer and compiling the model\n",
    "sgd = keras.optimizers.SGD(learning_rate = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aa1ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model, \n",
    "history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data = validation_generator,\n",
    "        epochs = 1000,\n",
    "        steps_per_epoch = int(np.ceil(20000/batch_size)),\n",
    "        validation_steps = int(np.ceil(5000/batch_size)),\n",
    "        callbacks = callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad91de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38390d56",
   "metadata": {},
   "source": [
    "Using Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9987ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Transfer Learning using the ResnetInceptionV2 Model\n",
    "with tf.device('/gpu:0'):\n",
    "    base_model = keras.applications.InceptionResNetV2(weights = \"imagenet\",\n",
    "                                                      include_top = False)\n",
    "    avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    dense = keras.layers.Dense(512, activation = \"relu\")(avg)\n",
    "    bn = keras.layers.BatchNormalization()(dense)\n",
    "    drop = keras.layers.Dropout(.2)(bn)\n",
    "    output = keras.layers.Dense(num_classes, activation = \"sigmoid\")(drop)\n",
    "    model = keras.models.Model(inputs = base_model.input, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fea2799",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1126 - accuracy: 0.9627\n",
      "Epoch 1: val_accuracy improved from -inf to 0.99340, saving model to working\\\n",
      "INFO:tensorflow:Assets written to: working\\assets\n",
      "625/625 [==============================] - 505s 791ms/step - loss: 0.1126 - accuracy: 0.9627 - val_loss: 0.0242 - val_accuracy: 0.9934\n",
      "Epoch 2/30\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9686\n",
      "Epoch 2: val_accuracy did not improve from 0.99340\n",
      "625/625 [==============================] - 459s 734ms/step - loss: 0.0874 - accuracy: 0.9686 - val_loss: 0.0271 - val_accuracy: 0.9912\n",
      "Epoch 3/30\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9703\n",
      "Epoch 3: val_accuracy improved from 0.99340 to 0.99420, saving model to working\\\n",
      "INFO:tensorflow:Assets written to: working\\assets\n",
      "625/625 [==============================] - 512s 819ms/step - loss: 0.0847 - accuracy: 0.9703 - val_loss: 0.0196 - val_accuracy: 0.9942\n",
      "Epoch 4/30\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.9706\n",
      "Epoch 4: val_accuracy did not improve from 0.99420\n",
      "625/625 [==============================] - 475s 760ms/step - loss: 0.0816 - accuracy: 0.9706 - val_loss: 0.0212 - val_accuracy: 0.9932\n",
      "Epoch 5/30\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.9736\n",
      "Epoch 5: val_accuracy did not improve from 0.99420\n",
      "625/625 [==============================] - 465s 744ms/step - loss: 0.0805 - accuracy: 0.9736 - val_loss: 0.0253 - val_accuracy: 0.9920\n"
     ]
    }
   ],
   "source": [
    "#Training the last layers of the model without changing the original model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "sgd = keras.optimizers.SGD(learning_rate = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = sgd,\n",
    "              metrics = [\"accuracy\"])\n",
    "\n",
    "history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data = validation_generator,\n",
    "        epochs = 30,\n",
    "        steps_per_epoch = int(np.ceil(20000/batch_size)),\n",
    "        validation_steps = int(np.ceil(5000/batch_size)),\n",
    "        callbacks = callbacks_list\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0f29f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(work + \"model_InceptionResNetV2_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7796425",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(base_model)\n",
    "del(model)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0628225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b76297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20bc4c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    model = tf.keras.models.load_model(work + \"model_InceptionResNetV2_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d44fe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9776\n",
      "Epoch 1: val_accuracy improved from -inf to 0.99479, saving model to working\\\n",
      "INFO:tensorflow:Assets written to: working\\assets\n",
      "625/625 [==============================] - 529s 829ms/step - loss: 0.0650 - accuracy: 0.9776 - val_loss: 0.0171 - val_accuracy: 0.9948\n",
      "Epoch 2/30\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.9794\n",
      "Epoch 2: val_accuracy did not improve from 0.99479\n",
      "625/625 [==============================] - 475s 760ms/step - loss: 0.0585 - accuracy: 0.9794 - val_loss: 0.0237 - val_accuracy: 0.9926\n",
      "Epoch 3/30\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9780\n",
      "Epoch 3: val_accuracy did not improve from 0.99479\n",
      "625/625 [==============================] - 478s 765ms/step - loss: 0.0587 - accuracy: 0.9780 - val_loss: 0.0228 - val_accuracy: 0.9932\n"
     ]
    }
   ],
   "source": [
    "#Training the entire model as the final layers have initialized earlier\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "sgd = keras.optimizers.SGD(learning_rate = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "    \n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = sgd,\n",
    "              metrics = [\"accuracy\"])\n",
    "with tf.device('/gpu:0'):\n",
    "    history_2 = model.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            epochs = 30,\n",
    "            steps_per_epoch = int(np.ceil(20000/batch_size)),\n",
    "            validation_steps = int(np.ceil(5000)/batch_size),\n",
    "            callbacks = callbacks_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e0a964d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: working/model_InceptionResNetV2_final_full\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(work + \"model_InceptionResNetV2_final_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "385aa2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('model_loss.json')\n",
    "model_loss = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31f6af54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss[\"model_InceptionResNetV2_final_full\"] = min(history_2.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cd554b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_loss.json', 'w') as f:\n",
    "    json.dump(model_loss, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f34c38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking losses of all the models trained by transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98ec2500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'InceptionResNetV2': 0.0615997314453125,\n",
       " 'model_NASNetLarge': 0.04065510258078575,\n",
       " 'model_ResNet152V2': 0.05378391593694687,\n",
       " 'model_MobileNetV3Large_Full': 0.6385003924369812,\n",
       " 'model_NASNetLarge_SGD_full': 0.017551414668560028,\n",
       " 'model_InceptionResNetV2_SGD_full': 0.04393969848752022,\n",
       " 'model_InceptionResNetV2_SGD_full_0.2': 0.060112982988357544,\n",
       " 'model_Xception_SGD_full_0.2': 0.05441661924123764,\n",
       " 'model_InceptionResNetV2_SGD_half_0.1_bn': 0.0679125040769577,\n",
       " 'model_InceptionV3_SGD_half_0.1_bn': 0.07481814175844193,\n",
       " 'model_InceptionResNetV2_final_full': 0.05845284461975098}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b89d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e654219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model = tf.keras.models.load_model(work + \"model_InceptionResNetV2_final_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0256cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting on the test images and creating the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f4613ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_generator)\n",
    "y_pred = [x[1] for x in pred]\n",
    "y_pred = np.array(y_pred)\n",
    "ids = test_generator.filenames\n",
    "test_x = np.sort([idx.split(\"\\\\\")[1].split(\".\")[0] for idx in ids])\n",
    "data_1 = pd.DataFrame({'id': test_x, 'label': y_pred}, columns=['id', 'label'])\n",
    "data_1[\"ids_sorted\"] = pd.to_numeric(data_1[\"id\"])\n",
    "data_1.sort_values(by = [\"ids_sorted\"], inplace=True)\n",
    "data_1.drop([\"ids_sorted\"], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30860b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1.to_csv(\"model_InceptionResNetV2_final_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daf2c0c",
   "metadata": {},
   "source": [
    "I got a final score of 0.044 logloss on Kaggle, which puts me in top 20 rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a26280a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b87e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating functions for kaggle\n",
    "# import zipfile\n",
    "\n",
    "# train_zip='/kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip'\n",
    "# zip_ref=zipfile.ZipFile(train_zip,'r')\n",
    "# zip_ref.extractall('/kaggle/working/')\n",
    "\n",
    "\n",
    "# work='/kaggle/working'\n",
    "# train_path='/kaggle/working/train/'\n",
    "# file_items=os.listdir(train_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
